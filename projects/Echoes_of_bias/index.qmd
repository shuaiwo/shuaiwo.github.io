---
title: "Echoes of Bias"
description: "Examine Challenges and Opportunities of AI in City Planning"
author: "Shuai Wang"
date: "2023-10-20"
categories: [Urban Tech, City Planning, Essay]
image: "Ai.png"
---

\n
\"Hey ChatGPT, picture a doctor for me.\"

![Images of doctors created by ChatGPT using DALL-E.](Ai.png)
\n Figure: Images of doctors created by ChatGPT using DALL-E (Author, 2024)

I entered the same prompt 10 times, and the outcome was startlingly uniform - white and mostly men. On the contrary, 75.7% of the US healthcare practitioners including doctors are female, and 74.4% are white in 2022, according to the US Bureau of Labor Statistics. There is a significant representation of white masculinity in image generation models powered by Artificial Intelligence (AI).

It's not just about doctors - this trend of white masculinity dominance spreads across AI's representation of various professions and categories. AI has reinforced the racial and gender disparities even more by tending to create images depicting individuals as white and male, particularly in scenarios involving authoritative roles, such as managers and CEOs.

What does this tell us? It's simple yet profound -- our AI mirrors our biases. The algorithms, fed with past data, often replicate societal stereotypes. AI aims to perform recurring data analysis and pattern-matching based on past reliable patterns and rule-based algorithms. Here's the real kicker: as these AI models weave their way into city planning and governance, these biases don't just linger; they amplify. It is essential to apply AI in city planning and governance with caution to ensure it minimizes the risks of biases and fosters urban innovative and social inclusivity.

Applying AI in city planning and governance presents bias and simplification of real-world issues. All data are inherently biased and have limitations as they are created by humans with either direct collection or indirect selection from human-placed things like sensors. As a consequence, the output result from the algorithm is likely to be biased as well, owing to the biased input data. For instance, the labels of pictures on ImageNet dataset contain biases of people as the input label data divide the images of humans into categories that can be discriminative, subjective and stereotypical. With the preset bias of people in the image labeling data, any algorithm that uses ImageNet as a data source can generate results that reinforce biased information. If biased personal data are widely used in city planning, governance and operations, it is very likely to pose a threat to the vulnerable groups that have already been suffering from biases. In addition, many social issues and challenges are too complex to be put into an algorithm. Plenty of urban problems cannot be simply captured by quantitative or qualitative data, as real-life problems consist of factors that cannot be measured precisely. There can only be a certain number of variables in one dataset, which also limits the ability of the algorithms to cover all the possible factors perfectly. Therefore, considering the potential consequences and challenges facing the application of AI in cities, it is necessary to use regulations to monitor the usage of AI.

While the risks of using AI should be carefully monitored, AI has extensive opportunities and potential to enhance evidence-based decision-making in city planning and governance. By using the high quality and large quantity of existing training data, AI can contribute to informed and efficient decision-making. For instance, AI can be used to survey feedback from residents to measure their satisfaction with services or their feelings about local development impacts. This could help to identify areas where face-to-face, in-depth conversations are needed, which could further benefit from AI-supported pattern detection. Furthermore, AI can facilitate the optimization of urban systems and service operations. For example, AI can be applied to identify the ridership difference between female and male populations with large amounts of socio-economic and traffic data, which informs future policy-making and contributes to further optimization of urban services. Therefore, AI can benefit urban planning and operations with data-driven decision-making, such as improving efficiency and promoting innovation.

AI practice in city planning, governance and operations should be regulated in a way that balances their benefits and harms, to minimize bias and to commit to innovation. For instance, the New York City AI Strategy intends to foster a thriving AI ecosystem and ensure the appropriate use of AI technology. The strategy aims to reduce potential biases by enhancing transparency, accountability, and public engagement in the development and deployment of AI solutions. Moreover, regulating the use of ML and AI does not mean stopping innovation in technology. In the New York City AI Strategy, the city supports ongoing AI literacy and skill-building needs by having robust educational infrastructure in place, and particular investment in place in public- and public-interest resources. In this way, by regulating the use of ML and AI cities, cities can foster a culture of innovation while protecting their citizens with privacy and inclusion.

In conclusion, AI offers great opportunities and potential to improve public engagement and evidence-based decision-making. Nevertheless, the essence of data bias and the simplification of real urban phenomena using AI can also threaten social equity and diversity. As a result, it is highly essential to use AI in cities with caution and care, such as minimizing bias and enhancing innovation. Furthermore, collaboration among various stakeholders in city development, such as planners, developers, policymakers, and researchers, should be encouraged to allow more transparency and up-to-date practice in AI. With the shared goal to implement AI more inclusively, cautiously and innovatively, the technology can contribute to the public good in the future.
